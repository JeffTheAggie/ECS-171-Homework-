{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECS 171 Homework 5\n",
    "## by, Jeffrey Ugochukwu\n",
    "### 1\n",
    "Load the data from the provided .csv file into a pandas dataframe, it contains a list of 1200 bitstrings which each have a length of 16 bits. Call the dataset S. We call two bitstrings A and B equivalent (A∼B) if you can flip one bit at a time starting from A to produce a sequence of strings A,s1,s2,...,sn,B∈S that are all within the dataset to get the string B. Through this notion of equivalence, we may define an equivalence relation on this set of bit strings. Using agglomerative clustering with a tolerance on distance for early stopping, we can compute the number of equivalence classes by counting the number of clusters. In order to do this, which linkage rule should be used (single-linkage, complete-linkage, or average-linkage), which distance function should be used (Euclidiean distance, Manhattan distance, or cosine distance), and what should the threshold distance be? Explain why you would pick these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>0.6</th>\n",
       "      <th>1.2</th>\n",
       "      <th>1.3</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.5</th>\n",
       "      <th>1.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.1  0.2  0.3  0.4  0.5  1  1.1  0.6  1.2  1.3  1.4  1.5  1.6  0.7  \\\n",
       "0     0    0    0    0    0    0  1    1    0    0    1    1    1    1    0   \n",
       "1     0    0    0    0    0    0  0    1    0    0    1    1    1    1    0   \n",
       "2     0    0    0    0    0    0  1    1    0    0    1    1    1    1    0   \n",
       "3     0    0    0    0    0    1  1    1    0    0    1    1    1    1    0   \n",
       "4     0    0    0    0    1    1  1    1    0    0    1    1    1    1    0   \n",
       "...  ..  ...  ...  ...  ...  ... ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1194  1    1    0    1    1    1  1    1    1    0    0    0    1    1    1   \n",
       "1195  1    1    0    1    1    1  1    1    1    0    0    0    1    1    1   \n",
       "1196  1    1    0    1    1    1  1    1    1    1    0    0    1    1    1   \n",
       "1197  1    1    0    1    1    1  1    1    1    1    1    1    1    1    1   \n",
       "1198  1    0    0    1    1    1  1    1    1    1    1    0    1    1    1   \n",
       "\n",
       "      0.8  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "...   ...  \n",
       "1194    1  \n",
       "1195    0  \n",
       "1196    1  \n",
       "1197    1  \n",
       "1198    1  \n",
       "\n",
       "[1199 rows x 16 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "#Importing Dataset\n",
    "S = pd.read_csv(\"bitstrings.csv\")\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe that we should use the single-linkage rule because we're checking individual bits to see how they're changing at a time. This would also mean that we would have to use Manhattan distance for this calculation since we have a high dimensionality of 16 bits and this can check the individual change per bit. Our threshold should be 1.0001 because the points given here range from 0 to 1, so finding the euclidean distance of this gives us the value of 1.0001 for the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\n",
    "Perform the clustering using the parameters you picked in Q1. How many equivalence classes (clusters) are there? Create a bar plot, showing the number of strings in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 7, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Single Linkage cluster\n",
    "cluster = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='single', distance_threshold = 1.0001)\n",
    "d = cluster.fit_predict(S)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7 7 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "#Labels of cluster\n",
    "print(cluster.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0  0.1  0.2  0.3  0.4  0.5  1  1.1  0.6  1.2  1.3  1.4  1.5  1.6  0.7  0.8\n",
       "0  1    0    1    0    0    1  0    0    0    0    0    1    1    0    0      10\n",
       "1  1    0    1    1    1    1  1    1    1    0    0    1    1    1    1       9\n",
       "        1    1    0    0    1  1    0    1    0    1    1    1    1    1       8\n",
       "0  1    0    0    0    1    1  1    0    1    0    1    0    0    0    1       8\n",
       "1  0    0    1    1    0    0  0    1    1    0    0    1    0    0    1       7\n",
       "                                                                              ..\n",
       "0  1    0    1    1    1    0  1    0    0    1    0    1    1    1    0       1\n",
       "                                                   1    1    0    1    0       1\n",
       "                            1  0    0    0    1    0    0    0    1    0       1\n",
       "                                                        1    0    0    0       1\n",
       "1  1    1    1    1    1    1  1    1    1    1    0    1    1    1    1       1\n",
       "Length: 784, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Value counts\n",
    "S.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\n",
    "Using this clustering, determine if 0000001101111100∼1011101101111101. What about 1001111011001001∼1001111011000000? (You need to show that you used this clustering to determine the answer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 7, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classification\n",
    "cluster = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='single', distance_threshold = 1.0001)\n",
    "d = cluster.fit_predict(S)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\n",
    "Redo the clustering on the dataset, but this time using both of the other linkage rules (keep everything else the same), and report the number of clusters for both. Is there any difference from the number of clusters you found in Q2? If so, explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([572, 572, 572, ..., 163, 284, 250], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Complete linkage\n",
    "cluster2 = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='complete', distance_threshold = 1.0001)\n",
    "d2 = cluster2.fit_predict(S)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0  0.1  0.2  0.3  0.4  0.5  1  1.1  0.6  1.2  1.3  1.4  1.5  1.6  0.7  0.8\n",
       "0  1    0    1    0    0    1  0    0    0    0    0    1    1    0    0      10\n",
       "1  1    0    1    1    1    1  1    1    1    0    0    1    1    1    1       9\n",
       "        1    1    0    0    1  1    0    1    0    1    1    1    1    1       8\n",
       "0  1    0    0    0    1    1  1    0    1    0    1    0    0    0    1       8\n",
       "1  0    0    1    1    0    0  0    1    1    0    0    1    0    0    1       7\n",
       "                                                                              ..\n",
       "0  1    0    1    1    1    0  1    0    0    1    0    1    1    1    0       1\n",
       "                                                   1    1    0    1    0       1\n",
       "                            1  0    0    0    1    0    0    0    1    0       1\n",
       "                                                        1    0    0    0       1\n",
       "1  1    1    1    1    1    1  1    1    1    1    0    1    1    1    1       1\n",
       "Length: 784, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Value counts\n",
    "S.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([134, 134, 134, ..., 256, 312, 468], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average linkage\n",
    "cluster3 = AgglomerativeClustering(n_clusters=None, affinity='manhattan', linkage='average', distance_threshold = 1.0001)\n",
    "d3 = cluster3.fit_predict(S)\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0  0.1  0.2  0.3  0.4  0.5  1  1.1  0.6  1.2  1.3  1.4  1.5  1.6  0.7  0.8\n",
       "0  1    0    1    0    0    1  0    0    0    0    0    1    1    0    0      10\n",
       "1  1    0    1    1    1    1  1    1    1    0    0    1    1    1    1       9\n",
       "        1    1    0    0    1  1    0    1    0    1    1    1    1    1       8\n",
       "0  1    0    0    0    1    1  1    0    1    0    1    0    0    0    1       8\n",
       "1  0    0    1    1    0    0  0    1    1    0    0    1    0    0    1       7\n",
       "                                                                              ..\n",
       "0  1    0    1    1    1    0  1    0    0    1    0    1    1    1    0       1\n",
       "                                                   1    1    0    1    0       1\n",
       "                            1  0    0    0    1    0    0    0    1    0       1\n",
       "                                                        1    0    0    0       1\n",
       "1  1    1    1    1    1    1  1    1    1    1    0    1    1    1    1       1\n",
       "Length: 784, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Value counts\n",
    "S.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value counts for the linkage methods appear to be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5\n",
    "Cluster the dataset again, this time using K-means clustering with the number of clusters set to the number you found in Q2. Create a bar plot for the size of the clusters. Compare with your plot in Q2, how do these results differ? Give an explanation for this difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(init='random', n_clusters=3, random_state=42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KMeans cluster\n",
    "kmeans = KMeans(\n",
    "   ...:     init=\"random\",\n",
    "   ...:     n_clusters=3,\n",
    "   ...:     n_init=10,\n",
    "   ...:     max_iter=300,\n",
    "   ...:     random_state=42\n",
    "   ...: )\n",
    "kmeans.fit(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3474.9299975751237"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KMeans inertia\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2939759 , 0.72289157, 0.10361446, 0.30843373, 0.10843373,\n",
       "        0.52289157, 0.7373494 , 0.71325301, 0.11084337, 0.45542169,\n",
       "        0.3060241 , 0.67951807, 0.7060241 , 0.4939759 , 0.08915663,\n",
       "        0.3253012 ],\n",
       "       [0.70351759, 0.0879397 , 0.11557789, 0.71105528, 0.30904523,\n",
       "        0.2839196 , 0.09798995, 0.09296482, 0.70854271, 0.89949749,\n",
       "        0.44723618, 0.29648241, 0.5201005 , 0.51507538, 0.50251256,\n",
       "        0.90201005],\n",
       "       [0.47668394, 0.65025907, 0.52072539, 0.93005181, 0.48445596,\n",
       "        0.69430052, 0.89119171, 0.90932642, 0.29015544, 0.69170984,\n",
       "        0.51554404, 0.3134715 , 0.91968912, 0.72279793, 0.9119171 ,\n",
       "        0.48445596]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KMeans cluster\n",
    "kmeans.cluster_centers_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
