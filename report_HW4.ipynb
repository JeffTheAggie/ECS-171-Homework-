{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECS 171 Homework 4\n",
    "## by, Jeffrey Ugochukwu\n",
    "### 1a\n",
    "Use the churn data set. Except for the Account Length, VMail Message, Day Mins, Day Calls, Eve Mins, Night Mins, Intl Mins, Intl Calls, CustServ Calls, Intl Plan, and Churn, drop the remaining columns from the dataset. Preprocess the data :\n",
    "Encode categorical features to numerical values using one-hot encoding.\n",
    "Use MinMaxScaler to transform your numerical attributes. One of the practices for training a Neural Network is to normalize your data to obtain a mean close to 0. Normalizing the data generally speeds up learning and leads to faster convergence.\n",
    "Develop a 4-layer artificial neural network (ANN) and specifically a feed-forward multilayer perceptron (with sigmoid activations and MSE loss function) to perform binary classification to classify 'Churn' based on other variables. For this, split the data into training and testing set by 70:30 and use the training set for training the model and the test set to evaluate the model performance. Use sgd optimizer with no momentum and keep it simple. Please note that this is a binary classification problem so select the right number of nodes accordingly for the output layer. Use gridsearch to determine the number of nodes in the hidden layers. Train this toy model on a single iteration. Get the layer weights and loss from the model. You donâ€™t need to use a callback since the current weights and loss will be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>no</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>197.4</td>\n",
       "      <td>244.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>no</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>195.5</td>\n",
       "      <td>254.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>121.2</td>\n",
       "      <td>162.6</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>61.9</td>\n",
       "      <td>196.9</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>148.3</td>\n",
       "      <td>186.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Account Length Int'l Plan  VMail Message  Day Mins  Day Calls  Eve Mins  \\\n",
       "0             128         no             25     265.1        110     197.4   \n",
       "1             107         no             26     161.6        123     195.5   \n",
       "2             137         no              0     243.4        114     121.2   \n",
       "3              84        yes              0     299.4         71      61.9   \n",
       "4              75        yes              0     166.7        113     148.3   \n",
       "\n",
       "   Night Mins  Intl Mins  Intl Calls  CustServ Calls  Churn?  \n",
       "0       244.7       10.0           3               1  False.  \n",
       "1       254.4       13.7           3               1  False.  \n",
       "2       162.6       12.2           5               0  False.  \n",
       "3       196.9        6.6           7               2  False.  \n",
       "4       186.9       10.1           3               3  False.  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Importing Churn dataset and dropping unnecessary columns\n",
    "df = pd.read_csv(\"churn.txt\")\n",
    "df.drop(['State', 'Area Code', 'Phone', 'VMail Plan', 'Day Charge', 'Eve Calls', 'Eve Charge', 'Night Calls', 'Night Charge', 'Intl Charge'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account Length</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Int'l Plan_no</th>\n",
       "      <th>Int'l Plan_yes</th>\n",
       "      <th>Churn?_True.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049587</td>\n",
       "      <td>-0.019608</td>\n",
       "      <td>0.511403</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.085510</td>\n",
       "      <td>0.191501</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.123967</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-0.078677</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.075062</td>\n",
       "      <td>0.243679</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.123967</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.387685</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>-0.333517</td>\n",
       "      <td>-0.250134</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.314050</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.706956</td>\n",
       "      <td>-0.139394</td>\n",
       "      <td>-0.659610</td>\n",
       "      <td>-0.065627</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.388430</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.049601</td>\n",
       "      <td>0.369697</td>\n",
       "      <td>-0.184493</td>\n",
       "      <td>-0.119419</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Account Length  VMail Message  Day Mins  Day Calls  Eve Mins  Night Mins  \\\n",
       "0        0.049587      -0.019608  0.511403   0.333333  0.085510    0.191501   \n",
       "1       -0.123967       0.019608 -0.078677   0.490909  0.075062    0.243679   \n",
       "2        0.123967      -1.000000  0.387685   0.381818 -0.333517   -0.250134   \n",
       "3       -0.314050      -1.000000  0.706956  -0.139394 -0.659610   -0.065627   \n",
       "4       -0.388430      -1.000000 -0.049601   0.369697 -0.184493   -0.119419   \n",
       "\n",
       "   Intl Mins  Intl Calls  CustServ Calls  Int'l Plan_no  Int'l Plan_yes  \\\n",
       "0       0.00        -0.7       -0.777778              1               0   \n",
       "1       0.37        -0.7       -0.777778              1               0   \n",
       "2       0.22        -0.5       -1.000000              1               0   \n",
       "3      -0.34        -0.3       -0.555556              0               1   \n",
       "4       0.01        -0.7       -0.333333              0               1   \n",
       "\n",
       "   Churn?_True.  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Organizing all of the numerical and categorical columns as separate varibales to be transformed and processed\n",
    "#Also dropped the \"Churn?_False.\" column since it's irrelevant since we need to classify that the values with churn existing\n",
    "numerical_features = df.select_dtypes(['int64', 'float64']).columns.values\n",
    "categorical_features = df.select_dtypes(['object']).columns.values\n",
    "numerical_transform = MinMaxScaler(feature_range=(-1,1))\n",
    "numerical_processed = numerical_transform.fit_transform(df[numerical_features])\n",
    "df_processed = pd.get_dummies(df, columns= categorical_features)\n",
    "df_processed.update(pd.DataFrame(numerical_processed, columns = numerical_features))\n",
    "df_processed.drop([\"Churn?_False.\"], axis = 1, inplace = True)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Account Length',\n",
       " 'VMail Message',\n",
       " 'Day Mins',\n",
       " 'Day Calls',\n",
       " 'Eve Mins',\n",
       " 'Night Mins',\n",
       " 'Intl Mins',\n",
       " 'Intl Calls',\n",
       " 'CustServ Calls',\n",
       " \"Int'l Plan_no\",\n",
       " \"Int'l Plan_yes\",\n",
       " 'Churn?_True.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking all of the names of the columns that currently exist\n",
    "list(df_processed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 821us/step - loss: 0.3844 - accuracy: 0.1499\n",
      "15/15 [==============================] - 0s 712us/step - loss: 0.3542 - accuracy: 0.1328\n",
      "59/59 [==============================] - 0s 818us/step - loss: 0.2652 - accuracy: 0.1975\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2398 - accuracy: 0.8351\n",
      "59/59 [==============================] - 0s 781us/step - loss: 0.2264 - accuracy: 0.8419\n",
      "15/15 [==============================] - 0s 657us/step - loss: 0.1991 - accuracy: 0.8801\n",
      "59/59 [==============================] - 1s 784us/step - loss: 0.3241 - accuracy: 0.1326\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2920 - accuracy: 0.1524\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.8597\n",
      "15/15 [==============================] - 0s 926us/step - loss: 0.1661 - accuracy: 0.8455\n",
      "59/59 [==============================] - 0s 941us/step - loss: 0.1778 - accuracy: 0.8501\n",
      "15/15 [==============================] - 0s 926us/step - loss: 0.1564 - accuracy: 0.8672\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.8561\n",
      "15/15 [==============================] - 0s 926us/step - loss: 0.1704 - accuracy: 0.8351\n",
      "59/59 [==============================] - 0s 822us/step - loss: 0.2254 - accuracy: 0.8436\n",
      "15/15 [==============================] - 0s 926us/step - loss: 0.1852 - accuracy: 0.8801\n",
      "59/59 [==============================] - 0s 946us/step - loss: 0.2061 - accuracy: 0.8674\n",
      "15/15 [==============================] - 0s 998us/step - loss: 0.1843 - accuracy: 0.8476\n",
      "59/59 [==============================] - 1s 780us/step - loss: 0.1999 - accuracy: 0.8597\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.8455\n",
      "59/59 [==============================] - 0s 911us/step - loss: 0.2147 - accuracy: 0.8501\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.8672\n",
      "59/59 [==============================] - 1s 899us/step - loss: 0.1801 - accuracy: 0.8561\n",
      "15/15 [==============================] - 0s 997us/step - loss: 0.1691 - accuracy: 0.8351\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.4086 - accuracy: 0.1581\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3806 - accuracy: 0.1199\n",
      "59/59 [==============================] - 1s 982us/step - loss: 0.4179 - accuracy: 0.1326\n",
      "15/15 [==============================] - 0s 712us/step - loss: 0.3728 - accuracy: 0.1524\n",
      "59/59 [==============================] - 0s 773us/step - loss: 0.2378 - accuracy: 0.7850\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2084 - accuracy: 0.8455\n",
      "59/59 [==============================] - 0s 836us/step - loss: 0.2722 - accuracy: 0.2150\n",
      "15/15 [==============================] - 0s 713us/step - loss: 0.2278 - accuracy: 0.8672\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.1440\n",
      "15/15 [==============================] - 0s 926us/step - loss: 0.2527 - accuracy: 0.2934\n",
      "59/59 [==============================] - 1s 847us/step - loss: 0.2713 - accuracy: 0.2564\n",
      "15/15 [==============================] - 0s 713us/step - loss: 0.2155 - accuracy: 0.8801\n",
      "59/59 [==============================] - 0s 796us/step - loss: 0.3909 - accuracy: 0.1326\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.3137 - accuracy: 0.1524\n",
      "59/59 [==============================] - 0s 794us/step - loss: 0.3194 - accuracy: 0.1403\n",
      "15/15 [==============================] - 0s 713us/step - loss: 0.2655 - accuracy: 0.1545\n",
      "59/59 [==============================] - 0s 812us/step - loss: 0.2014 - accuracy: 0.8501\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.1777 - accuracy: 0.8672\n",
      "59/59 [==============================] - 1s 897us/step - loss: 0.2254 - accuracy: 0.8561\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2011 - accuracy: 0.8351\n",
      "59/59 [==============================] - 0s 872us/step - loss: 0.1992 - accuracy: 0.8419\n",
      "15/15 [==============================] - 0s 926us/step - loss: 0.1625 - accuracy: 0.8801\n",
      "59/59 [==============================] - 0s 819us/step - loss: 0.2012 - accuracy: 0.8674\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.1778 - accuracy: 0.8476\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.1908 - accuracy: 0.8597\n",
      "15/15 [==============================] - 0s 712us/step - loss: 0.1687 - accuracy: 0.8455\n",
      "59/59 [==============================] - 0s 895us/step - loss: 0.6036 - accuracy: 0.1499\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.5469 - accuracy: 0.1328\n",
      "59/59 [==============================] - 0s 857us/step - loss: 0.3984 - accuracy: 0.1439\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.3192 - accuracy: 0.1649\n",
      "59/59 [==============================] - 0s 887us/step - loss: 0.2868 - accuracy: 0.2014\n",
      "15/15 [==============================] - 0s 797us/step - loss: 0.2264 - accuracy: 0.8801\n",
      "59/59 [==============================] - 0s 948us/step - loss: 0.3576 - accuracy: 0.1326\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2958 - accuracy: 0.1524\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.2435 - accuracy: 0.5535\n",
      "15/15 [==============================] - 0s 712us/step - loss: 0.2006 - accuracy: 0.8455\n",
      "73/73 [==============================] - 1s 736us/step - loss: 0.3595 - accuracy: 0.1484\n",
      "Best: 0.855115 using {'layer1': 3, 'layer2': 5}\n"
     ]
    }
   ],
   "source": [
    "#Building the ANN model\n",
    "train, test = train_test_split(df_processed, train_size=0.7, random_state=1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "def create_model(layer1=3, layer2=5):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(11,)))\n",
    "    model.add(Activation('sigmoid')) \n",
    "    model.add(Dense(layer2))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy']) \n",
    "    return model\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "param_grid = {'layer1':[3, 5, 7], 'layer2':[3, 5]}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(train.drop(columns=['Churn?_True.']), train['Churn?_True.'])\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b\n",
    "For the ANN in part a), calculate the first round of weight updates with back-propagation with paper and pencil for the two final layers (output to 2nd hidden layer; 2nd hidden layer to 1st hidden layer) for only the first sample. Limit this calculation to only the weights corresponding to (i) the single output node and (ii) a single hidden node from the 2nd hidden layer. These weights also include the bias. You can initialize all weights to zero except the weights that you are calculating, which can be initialized to 1. All nodes within the same layer will have the same weights and gradients. Confirm that the numbers you calculated are the same as those produced by the code and provide both your calculations and the code output. Make sure that the loss function used in your hand calculation is the same as the one used in Keras. If your calculations do not agree, find out why. Provide both calculations made by hand (scanned image and using a calculator/ computer to verify the results for each step is fine) and corresponding output from the program that shows that both are in agreement. Include all your assumptions in your answer. For this problem, it is sufficient to calculate a single incoming weight and the bias for each layer. This is because we are initializing all layers of the network to non-random, identical values (per layer). As a result the gradients will be the same across each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Logistic Regression model for ANN\n",
    "mpg_x = np.array(df_processed['Account Length']).reshape(-1,1)\n",
    "mpg_y = np.array(df_processed[\"Churn?_True.\"])\n",
    "mpg_x_train,mpg_x_test,mpg_y_train,mpg_y_test = train_test_split(mpg_x,mpg_y,test_size=0.3)\n",
    "mpg_log = LogisticRegression()\n",
    "mpg_log.fit(mpg_x_train, mpg_y_train)\n",
    "mpg_y_pred = mpg_log.predict(np.array(mpg_x_test))\n",
    "mpg_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.151"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding MSE for ANN\n",
    "mean_squared_error(mpg_y_test, mpg_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\n",
    "Create 2 dummy input samples and use the ANN model which you trained in Q1a to classify the output. Include your code and the classified output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account Length</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Int'l Plan_no</th>\n",
       "      <th>Int'l Plan_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.177798</td>\n",
       "      <td>-0.691469</td>\n",
       "      <td>0.029285</td>\n",
       "      <td>0.218299</td>\n",
       "      <td>0.104062</td>\n",
       "      <td>-0.043222</td>\n",
       "      <td>0.023759</td>\n",
       "      <td>-0.552679</td>\n",
       "      <td>-0.652522</td>\n",
       "      <td>0.907844</td>\n",
       "      <td>0.092156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.331476</td>\n",
       "      <td>0.535288</td>\n",
       "      <td>0.309476</td>\n",
       "      <td>0.245939</td>\n",
       "      <td>0.277337</td>\n",
       "      <td>0.272998</td>\n",
       "      <td>0.277326</td>\n",
       "      <td>0.241756</td>\n",
       "      <td>0.293857</td>\n",
       "      <td>0.289308</td>\n",
       "      <td>0.289308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.766291</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.404959</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.177309</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>-0.088260</td>\n",
       "      <td>-0.224314</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.181818</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.034778</td>\n",
       "      <td>0.224242</td>\n",
       "      <td>0.100907</td>\n",
       "      <td>-0.044648</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.041322</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.236032</td>\n",
       "      <td>0.381818</td>\n",
       "      <td>0.297223</td>\n",
       "      <td>0.138784</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Account Length  VMail Message     Day Mins    Day Calls     Eve Mins  \\\n",
       "count     2333.000000    2333.000000  2333.000000  2333.000000  2333.000000   \n",
       "mean        -0.177798      -0.691469     0.029285     0.218299     0.104062   \n",
       "std          0.331476       0.535288     0.309476     0.245939     0.277337   \n",
       "min         -1.000000      -1.000000    -1.000000    -1.000000    -0.766291   \n",
       "25%         -0.404959      -1.000000    -0.177309     0.054545    -0.088260   \n",
       "50%         -0.181818      -1.000000     0.034778     0.224242     0.100907   \n",
       "75%          0.041322      -0.333333     0.236032     0.381818     0.297223   \n",
       "max          1.000000       1.000000     0.977195     1.000000     0.989552   \n",
       "\n",
       "        Night Mins    Intl Mins   Intl Calls  CustServ Calls  Int'l Plan_no  \\\n",
       "count  2333.000000  2333.000000  2333.000000     2333.000000    2333.000000   \n",
       "mean     -0.043222     0.023759    -0.552679       -0.652522       0.907844   \n",
       "std       0.272998     0.277326     0.241756        0.293857       0.289308   \n",
       "min      -1.000000    -1.000000    -1.000000       -1.000000       0.000000   \n",
       "25%      -0.224314    -0.150000    -0.700000       -0.777778       1.000000   \n",
       "50%      -0.044648     0.030000    -0.600000       -0.777778       1.000000   \n",
       "75%       0.138784     0.200000    -0.400000       -0.555556       1.000000   \n",
       "max       1.000000     1.000000     0.900000        1.000000       1.000000   \n",
       "\n",
       "       Int'l Plan_yes  \n",
       "count     2333.000000  \n",
       "mean         0.092156  \n",
       "std          0.289308  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the model using Train Test Split\n",
    "xtrain = train.iloc[:, 0:11]\n",
    "ytrain = train.iloc[:, 11:12]\n",
    "xtest = test.iloc[:, 0:11]\n",
    "ytest = test.iloc[:, 11:12]\n",
    "model.fit(xtrain, ytrain, epochs = 350, verbose = 0)\n",
    "xtrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 818us/step - loss: 0.7731 - accuracy: 0.0962\n",
      "15/15 [==============================] - 0s 783us/step - loss: 0.2917 - accuracy: 0.3901\n",
      "59/59 [==============================] - 0s 801us/step - loss: 0.5996 - accuracy: 0.1006\n",
      "15/15 [==============================] - 0s 713us/step - loss: 0.2465 - accuracy: 0.6146\n",
      "59/59 [==============================] - 1s 930us/step - loss: 0.5394 - accuracy: 0.1576\n",
      "15/15 [==============================] - 0s 802us/step - loss: 0.2394 - accuracy: 0.6124\n",
      "59/59 [==============================] - 0s 914us/step - loss: 0.6916 - accuracy: 0.0947\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2657 - accuracy: 0.3863\n",
      "59/59 [==============================] - 0s 845us/step - loss: 0.4694 - accuracy: 0.1585\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.6155\n",
      "59/59 [==============================] - 0s 850us/step - loss: 0.4547 - accuracy: 0.1574\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.2414 - accuracy: 0.6097\n",
      "59/59 [==============================] - 1s 908us/step - loss: 0.4758 - accuracy: 0.1577\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2384 - accuracy: 0.6146\n",
      "59/59 [==============================] - 0s 913us/step - loss: 0.5388 - accuracy: 0.1577\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.2378 - accuracy: 0.6124\n",
      "59/59 [==============================] - 0s 762us/step - loss: 0.5145 - accuracy: 0.1592\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2371 - accuracy: 0.6137\n",
      "59/59 [==============================] - 0s 884us/step - loss: 0.5044 - accuracy: 0.1585\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.2374 - accuracy: 0.6155\n",
      "59/59 [==============================] - 0s 917us/step - loss: 0.5202 - accuracy: 0.1574\n",
      "15/15 [==============================] - 0s 926us/step - loss: 0.2390 - accuracy: 0.6097\n",
      "59/59 [==============================] - 0s 832us/step - loss: 0.4605 - accuracy: 0.1577\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.2390 - accuracy: 0.6146\n",
      "59/59 [==============================] - 0s 799us/step - loss: 0.8124 - accuracy: 0.0969\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.3033 - accuracy: 0.3876\n",
      "59/59 [==============================] - 0s 823us/step - loss: 0.8199 - accuracy: 0.0947\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.3041 - accuracy: 0.3863\n",
      "59/59 [==============================] - 0s 842us/step - loss: 0.5674 - accuracy: 0.1517\n",
      "15/15 [==============================] - 0s 786us/step - loss: 0.2396 - accuracy: 0.6155\n",
      "59/59 [==============================] - 1s 850us/step - loss: 0.6109 - accuracy: 0.1023\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2442 - accuracy: 0.6097\n",
      "59/59 [==============================] - 0s 821us/step - loss: 0.6523 - accuracy: 0.0957\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.2508 - accuracy: 0.4140\n",
      "59/59 [==============================] - 0s 892us/step - loss: 0.6134 - accuracy: 0.1060\n",
      "15/15 [==============================] - 0s 712us/step - loss: 0.2416 - accuracy: 0.6124\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.7840 - accuracy: 0.0947\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2745 - accuracy: 0.3863\n",
      "59/59 [==============================] - 1s 853us/step - loss: 0.6862 - accuracy: 0.0952\n",
      "15/15 [==============================] - 0s 788us/step - loss: 0.2554 - accuracy: 0.3843\n",
      "59/59 [==============================] - 0s 966us/step - loss: 0.4975 - accuracy: 0.1574\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.2386 - accuracy: 0.6097\n",
      "59/59 [==============================] - 0s 921us/step - loss: 0.5384 - accuracy: 0.1577\n",
      "15/15 [==============================] - 0s 734us/step - loss: 0.2378 - accuracy: 0.6146\n",
      "59/59 [==============================] - 0s 984us/step - loss: 0.4929 - accuracy: 0.1576\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2382 - accuracy: 0.6124\n",
      "59/59 [==============================] - 1s 847us/step - loss: 0.5092 - accuracy: 0.1592\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2370 - accuracy: 0.6137\n",
      "59/59 [==============================] - 0s 951us/step - loss: 0.4893 - accuracy: 0.1585\n",
      "15/15 [==============================] - 0s 859us/step - loss: 0.2377 - accuracy: 0.6155\n",
      "59/59 [==============================] - 0s 971us/step - loss: 1.0643 - accuracy: 0.0962\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.3980 - accuracy: 0.3901\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.7894 - accuracy: 0.0957\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2787 - accuracy: 0.3854\n",
      "59/59 [==============================] - 0s 932us/step - loss: 0.6344 - accuracy: 0.1009\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2435 - accuracy: 0.6124\n",
      "59/59 [==============================] - 0s 997us/step - loss: 0.7374 - accuracy: 0.0947\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.2668 - accuracy: 0.3863\n",
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.1318\n",
      "15/15 [==============================] - 0s 856us/step - loss: 0.2378 - accuracy: 0.6155\n",
      "73/73 [==============================] - 0s 895us/step - loss: 0.7461 - accuracy: 0.0960\n",
      "Best: 0.613196 using {'layer1': 3, 'layer2': 5}\n"
     ]
    }
   ],
   "source": [
    "#Created ANN Model\n",
    "train, test = train_test_split(df_processed, train_size=0.7, random_state=1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "def create_model(layer1=3, layer2=5):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(11,)))\n",
    "    model.add(Activation('sigmoid')) \n",
    "    model.add(Dense(layer2))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy']) \n",
    "    return model\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "param_grid = {'layer1':[3, 5, 7], 'layer2':[3, 5]}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(train.drop(columns=['Churn?_True.']), train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\n",
    "Change the hidden layer activation functions to ReLU, the output layer activation to softmax, and the loss function to cross-entropy. Is this a better choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 1s 990us/step - loss: 0.7658 - accuracy: 0.1499\n",
      "15/15 [==============================] - 0s 998us/step - loss: 0.6910 - accuracy: 0.1328\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.6538 - accuracy: 0.1439\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.6173 - accuracy: 0.1649\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.6891 - accuracy: 0.1581\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6664 - accuracy: 0.1199\n",
      "59/59 [==============================] - 1s 980us/step - loss: 0.8004 - accuracy: 0.1326\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.7131 - accuracy: 0.1524\n",
      "59/59 [==============================] - 1s 4ms/step - loss: 0.7288 - accuracy: 0.1403\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6609 - accuracy: 0.1545\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.6169 - accuracy: 0.1499\n",
      "15/15 [==============================] - 0s 855us/step - loss: 0.5627 - accuracy: 0.1328\n",
      "59/59 [==============================] - 1s 860us/step - loss: 0.7015 - accuracy: 0.1439\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.1649\n",
      "59/59 [==============================] - 1s 994us/step - loss: 0.6154 - accuracy: 0.1581\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5244 - accuracy: 0.1199\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.6807 - accuracy: 0.1326\n",
      "15/15 [==============================] - 0s 929us/step - loss: 0.6446 - accuracy: 0.1524\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.5689 - accuracy: 0.1403\n",
      "15/15 [==============================] - 0s 1000us/step - loss: 0.4994 - accuracy: 0.1545\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.6792 - accuracy: 0.1499\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.1328\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.6778 - accuracy: 0.1439\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.1649\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.7102 - accuracy: 0.1581\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.1199\n",
      "59/59 [==============================] - 1s 929us/step - loss: 0.7297 - accuracy: 0.1326\n",
      "15/15 [==============================] - 0s 926us/step - loss: 0.6809 - accuracy: 0.1524\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.6211 - accuracy: 0.1403\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5698 - accuracy: 0.1545\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.8648 - accuracy: 0.1499\n",
      "15/15 [==============================] - 0s 997us/step - loss: 0.7126 - accuracy: 0.1328\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.7131 - accuracy: 0.1439\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.1649\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.5764 - accuracy: 0.1581\n",
      "15/15 [==============================] - 0s 926us/step - loss: 0.4569 - accuracy: 0.1199\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.6424 - accuracy: 0.1326\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.1524\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.5775 - accuracy: 0.1403\n",
      "15/15 [==============================] - 0s 997us/step - loss: 0.5218 - accuracy: 0.1545\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.6395 - accuracy: 0.1499\n",
      "15/15 [==============================] - 0s 925us/step - loss: 0.5501 - accuracy: 0.1328\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.5692 - accuracy: 0.1439\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.1649\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.7819 - accuracy: 0.1581\n",
      "15/15 [==============================] - 0s 926us/step - loss: 0.6748 - accuracy: 0.1199\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.6208 - accuracy: 0.1326\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.5446 - accuracy: 0.1524\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.4143 - accuracy: 0.1403\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3969 - accuracy: 0.1545\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.7963 - accuracy: 0.1499\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.1328\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.8319 - accuracy: 0.1439\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.1649\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.6482 - accuracy: 0.1581\n",
      "15/15 [==============================] - 0s 784us/step - loss: 0.5047 - accuracy: 0.1199\n",
      "59/59 [==============================] - 1s 993us/step - loss: 0.9812 - accuracy: 0.1326\n",
      "15/15 [==============================] - 0s 926us/step - loss: 0.7394 - accuracy: 0.1524\n",
      "59/59 [==============================] - 1s 1ms/step - loss: 0.7416 - accuracy: 0.1403\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6174 - accuracy: 0.1545\n",
      "73/73 [==============================] - 1s 1ms/step - loss: 0.6404 - accuracy: 0.1484\n",
      "Best: 0.144885 using {'layer1': 3, 'layer2': 3}\n"
     ]
    }
   ],
   "source": [
    "#Building the ANN model\n",
    "train, test = train_test_split(df_processed, train_size=0.7, random_state=1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "def create_model(layer1=3, layer2=5):\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(layer1, input_shape=(11,)))\n",
    "    model.add(Activation(tf.nn.relu)) \n",
    "    model.add(Dense(layer2))\n",
    "    model.add(Activation(tf.nn.relu))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss= 'binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "param_grid = {'layer1':[3, 5, 7], 'layer2':[3, 5]}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(train.drop(columns=['Churn?_True.']), train['Churn?_True.'])\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the parameters to ReLU, Cross Entropy, and Softmax actually worsens the performance of the model where it has a best accuracy level of 0.144885, but the original ANN model had a best accuracy level of 0.855115. Therefore, changing the original paramters was a poor choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\n",
    "Describe the trade-off between a large hidden layer and a small one. What are the benefits, what are the drawbacks? Also, describe the benefits and drawbacks of using a large or small values for learning rate in a NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "The tradeoffs using a large hidden layer in a neural network is that it decreases training training error but reduces generalization in classification. A small hidden would actually provide the inverse effect of what was explained for the tradeoffs in a large hidden layer. The tradeoffs in using a small learning rate for a neural network would be that this would require more epochs due to the small changes in weights per update, but it improves the convergence of a model to reach a specific values. The tradeoffs for a large learning rate be that it would require less eppchs, but it would make it harder for the model to converge to a value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
